{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13c1415c-0b6a-474e-b4f6-5f78d304a04d",
   "metadata": {},
   "source": [
    "#### Trigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "362107c0-571b-439f-a583-88fec9d3c688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to /Users/zs74qz/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/zs74qz/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "from nltk.util import trigrams\n",
    "from nltk.probability import FreqDist, ConditionalFreqDist\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "# Ensure the Reuters dataset is downloaded\n",
    "nltk.download(\"reuters\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e60dc8-62bd-4776-98ef-34701239533d",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "221a67af-5775-4198-b195-3ad34ee6a8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = reuters.sents()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb03f5e-6a23-4a5b-8df4-a9afc96b4565",
   "metadata": {},
   "source": [
    "Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68ad4f36-5cff-4a22-957b-defc4a60ba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentences):\n",
    "    cleaned_text = []\n",
    "    for sentence in sentences:\n",
    "        cleaned_sentence = [word.lower() for word in sentence]\n",
    "        cleaned_text.append(cleaned_sentence)\n",
    "    return cleaned_text\n",
    "\n",
    "sentences = preprocess(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcefb0b-de9a-4416-acce-f7033e9cc399",
   "metadata": {},
   "source": [
    "Build trigram frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "491ab1f0-e9a1-4a72-a239-b98d53eab7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "# Count occurrences of trigrams and bigrams\n",
    "for sentence in sentences:\n",
    "    for w1, w2, w3 in trigrams(sentence, pad_left=True, pad_right=True):\n",
    "        trigram_model[(w1, w2)][w3] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5802b87-b349-4c4e-98c8-2da977d1e331",
   "metadata": {},
   "source": [
    "Convert counts to probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed9a0227-d6ac-4ebd-97ed-1a5430cf69d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_probs = {\n",
    "    context: {w3: count / sum(context_counts.values()) for w3, count in context_counts.items()}\n",
    "    for context, context_counts in trigram_model.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a8d979-56d8-4e70-be0b-2d54fb1d781e",
   "metadata": {},
   "source": [
    "Generate text using the trigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65ea1829-50d7-4822-beab-fda0e0f33260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text using the trigram model\n",
    "def generate_text(trigram_probs, start_words, num_words=20):\n",
    "    w1, w2 = start_words\n",
    "    generated_text = [w1, w2]\n",
    "    \n",
    "    for _ in range(num_words):\n",
    "        next_word_candidates = trigram_probs.get((w1, w2), {})\n",
    "        if not next_word_candidates:\n",
    "            break\n",
    "        next_word = random.choices(\n",
    "            population=list(next_word_candidates.keys()),\n",
    "            weights=list(next_word_candidates.values()),\n",
    "            k=1\n",
    "        )[0]\n",
    "        generated_text.append(next_word)\n",
    "        w1, w2 = w2, next_word  # Shift context window\n",
    "    \n",
    "    # print(generated_text)\n",
    "    return ' '.join([str(word) for word in generated_text if word != None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aae4f3ef-0ba7-4603-b615-cd5835e0b3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:\n",
      "The course\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "\n",
    "# Example: Generate text\n",
    "start_words = (None, None)  # Using padding for start\n",
    "start_words = (\"the\", \"course\") # Note that words should b\n",
    "generated = generate_text(trigram_probs, start_words, num_words=50)\n",
    "print(\"Generated text:\")\n",
    "print(generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4a5326-fc2e-47ac-96cd-3a97016f18f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
