{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e5a9e28-680a-4347-9c2c-34b6bd6d6556",
   "metadata": {},
   "source": [
    "### Web Intelligence - Exercise 10"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this exercise, we will explore several prominent techniques for learning word representations. First, we will implement a matrix decomposition-based word embedding model, **Latent Semantic Analysis (LSA)**. These models leverage matrix factorization to capture semantic relationships in text, providing an introduction to the underlying principles of word representation.\n",
    "\n",
    "Next, we will implement a neural-based approach, the **SkipGram** model of the **Word2Vec** framework. The SkipGram architecture is designed to predict surrounding context words given a target word, effectively learning word representations that capture meaningful relationships between words in a corpus.\n",
    "\n",
    "We will work on the [CMU Book Summary](https://www.cs.cmu.edu/~dbamman/booksummaries.html) dataset that consists of plot summaries for $16,559$ books extracted from Wikipedia. Throughout the exercise, we will analyze and compare these methods, discussing their advantages, limitations, and practical applications in natural language processing tasks. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c716960bb166a2b2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Question 1.** In this exercise, we will implement the Latent Semantic Analysis (LSA)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1e86595d594d43a"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fff37314-ed5b-4bc0-9d65-9a7532fbf904",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T09:59:29.734761900Z",
     "start_time": "2025-01-14T09:59:21.044742700Z"
    }
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "# For loading the dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Preprocessing packages\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a29251f-9d2d-4e95-89dd-b2601ef9a5b9",
   "metadata": {},
   "source": [
    "Load the dataset and preprocess the book summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e016111-703e-455f-9bb2-57a9cf5b4831",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T09:59:32.920420600Z",
     "start_time": "2025-01-14T09:59:29.733760600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the CMU Book Summary Corpus dataset and get all the summaries.\n",
    "ld = load_dataset(\"textminr/cmu-book-summaries\")['train']\n",
    "summaries = [data['summary'] for data in ld]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18d66ecc6aeec364",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T09:59:55.652793200Z",
     "start_time": "2025-01-14T09:59:32.923331600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Pre-processing text:   0%|          | 0/16559 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c531e91310de4ecbb162dbf2f855fbe8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Complete the following preprocessing steps:\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def preprocess_texts(texts, stop_words):\n",
    "    \n",
    "    # Initialize the lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    cleaned_texts = []\n",
    "    for text in tqdm(texts, desc=\"Pre-processing text\"):\n",
    "        \n",
    "        # 1. Lowercase the text\n",
    "        text = text.lower()\n",
    "        \n",
    "        # 3. Remove punctuation and special characters\n",
    "        text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "        \n",
    "        # 4. Tokenize the text\n",
    "        words = word_tokenize(text)\n",
    "        \n",
    "        # 5. Remove stopwords\n",
    "        words = [word for word in words if word not in stop_words]\n",
    "        \n",
    "        # 6. Lemmatize the tokens \n",
    "        words = [lemmatizer.lemmatize(word) for word in words]\n",
    "        \n",
    "        # Join tokens back into a single string\n",
    "        cleaned_texts.append(\" \".join(words))\n",
    "        \n",
    "    return cleaned_texts\n",
    "\n",
    "# Run the preprocessing function on the summaries\n",
    "corpus = preprocess_texts(summaries, stop_words=stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca1ce7808d87eda9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T09:59:55.667948100Z",
     "start_time": "2025-01-14T09:59:55.656825800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Old Major, the old boar on the Manor Farm, calls the animals on the farm for a meeting, where he co\n",
      "Preprocessed: old major old boar manor farm call animal farm meeting compare human parasite teach animal revolutio\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# You can compare the original and preprocessed summaries to see the difference.\n",
    "print(f\"Original: {summaries[0][:100]}\")\n",
    "print(f\"Preprocessed: {corpus[0][:100]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e55aea1-60e1-4599-8b5d-329f9b056c52",
   "metadata": {},
   "source": [
    "Construct the Document-Term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89c0781140bd436c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T09:59:58.204866200Z",
     "start_time": "2025-01-14T09:59:55.669959200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Terms:\n",
      " ['aaron' 'abandon' 'abandoned' 'abandoning' 'abandonment' 'abbess' 'abbey'\n",
      " 'abbot' 'abby' 'abducted']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Note: you can only consider the top 'N' words ordered by term frequency across the corpus.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vocab_size = 10000\n",
    "\n",
    "# Initialize the vectorizer\n",
    "vectorizer = CountVectorizer(stop_words=\"english\", max_features=vocab_size)\n",
    "\n",
    "# Fit and transform the vectorizer to the preprocessed corpus\n",
    "dt_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Get feature names (words)\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "# Display the first few terms\n",
    "print(\"\\nTerms:\\n\", terms[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e7add3-344f-483d-b89c-7304d62fa377",
   "metadata": {},
   "source": [
    "Construct the Term Frequency-Inverse Document Frequency (TF-IDF) Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2e0cdbde08a54f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T09:59:58.315969500Z",
     "start_time": "2025-01-14T09:59:58.205886400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Matrix:\n",
      "   (0, 28)\t0.04150504697109791\n",
      "  (0, 59)\t0.017880438439147568\n",
      "  (0, 62)\t0.024050614704513258\n",
      "  (0, 65)\t0.02148900220953582\n",
      "  (0, 101)\t0.019971252959796713\n",
      "  (0, 106)\t0.025405365080079376\n",
      "  (0, 110)\t0.023893419238681803\n",
      "  (0, 144)\t0.023427409569694274\n",
      "  (0, 146)\t0.028160637656986585\n",
      "  (0, 249)\t0.09254085191660141\n",
      "  (0, 285)\t0.020202945121143484\n",
      "  (0, 294)\t0.02759108894982344\n",
      "  (0, 306)\t0.024863156853871606\n",
      "  (0, 382)\t0.5899226349451504\n",
      "  (0, 399)\t0.03845058365259945\n",
      "  (0, 448)\t0.013862127897737705\n",
      "  (0, 491)\t0.015845144349549038\n",
      "  (0, 499)\t0.019013388868692853\n",
      "  (0, 563)\t0.021664340850956573\n",
      "  (0, 598)\t0.021980774729014246\n",
      "  (0, 631)\t0.012484875364678306\n",
      "  (0, 636)\t0.03216995352535589\n",
      "  (0, 717)\t0.010649333876096276\n",
      "  (0, 831)\t0.01343579505830276\n",
      "  (0, 846)\t0.042099843524759734\n",
      "  :\t:\n",
      "  (4, 8803)\t0.03212315565655537\n",
      "  (4, 8806)\t0.047354241570513426\n",
      "  (4, 8826)\t0.046643489355269636\n",
      "  (4, 8836)\t0.03794523028781552\n",
      "  (4, 8847)\t0.03692569007328962\n",
      "  (4, 8967)\t0.04647512558107003\n",
      "  (4, 8969)\t0.10659094823534634\n",
      "  (4, 9066)\t0.02479750248348664\n",
      "  (4, 9084)\t0.06939222706937924\n",
      "  (4, 9087)\t0.06602463613155343\n",
      "  (4, 9199)\t0.03991145776149882\n",
      "  (4, 9257)\t0.024611772329650297\n",
      "  (4, 9432)\t0.05243631319854337\n",
      "  (4, 9445)\t0.0372041459457171\n",
      "  (4, 9486)\t0.04300405518087491\n",
      "  (4, 9556)\t0.04039535445172215\n",
      "  (4, 9586)\t0.04145946759374981\n",
      "  (4, 9707)\t0.04261530303134514\n",
      "  (4, 9713)\t0.02204436082781455\n",
      "  (4, 9756)\t0.01888662974228088\n",
      "  (4, 9763)\t0.03224710868300664\n",
      "  (4, 9907)\t0.07756112384943895\n",
      "  (4, 9963)\t0.01745265777219193\n",
      "  (4, 9974)\t0.01960973232585562\n",
      "  (4, 9998)\t0.28487400854121814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Initialize the transformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "# Fit and transform the document-term matrix to the TF-IDF matrix\n",
    "tfidf_matrix = tfidf_transformer.fit_transform(dt_matrix)\n",
    "\n",
    "# Display the first few terms\n",
    "print(\"\\nTF-IDF Matrix:\\n\", tfidf_matrix[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5117d862-2934-44b2-9ba8-11bdfaa7f20a",
   "metadata": {},
   "source": [
    "Perfom Singular Value Decomposition (SVD) and Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45228affb9bf0d37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T09:59:59.347185900Z",
     "start_time": "2025-01-14T09:59:58.317968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top k- singular values:\n",
      " [17.82432879  7.94587596  6.97479132  6.25583585  5.92562977  5.66415625\n",
      "  5.59209614  5.55013998  5.38315779  5.1758549   5.10314635  5.07500647\n",
      "  4.96575891  4.92335685  4.8769072   4.82142292  4.79849963  4.77217133\n",
      "  4.74419834  4.64729459  4.6247623   4.60609472  4.57410815  4.52926954\n",
      "  4.51877933  4.4791294   4.46241974  4.44398562  4.43039021  4.39791334\n",
      "  4.36031844  4.34162853]\n"
     ]
    }
   ],
   "source": [
    "k = 32\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse.linalg import svds\n",
    "U, S, Vh = svds(tfidf_matrix, k=k)\n",
    "\n",
    "index = np.argsort(S)[::-1]\n",
    "U, S, Vh = U[:, index], S[index], Vh[index]\n",
    "\n",
    "# Print the singular values\n",
    "print(\"\\nTop k- singular values:\\n\", S)\n",
    "\n",
    "# Define the word embeddings\n",
    "# Note that the columns of SVh.T define the word embeddings, i.e. rows of the VhS\n",
    "# SVh.T is also equal to U^TX so the rows of (X^TU) also correspond the same word embeddings.\n",
    "word_embeddings = np.dot(np.diag(S), Vh).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4d9622-4ff7-4016-8a9c-d0a7e6aade9e",
   "metadata": {},
   "source": [
    "Generate Word Embeddings and Analyze Similarity Between Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2aac9536b614fae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:00:00.131087400Z",
     "start_time": "2025-01-14T09:59:59.350186Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 600x400 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "\n",
    "words_to_explore= [\n",
    "    'king', 'queen', 'woman', 'man', 'man', 'woman', 'boy', 'daughter', \n",
    "    #'dog', 'cat', 'horse', 'elephant', 'fish', 'bird', 'lizard', 'snake',\n",
    "    #'doctor', 'nurse', 'scientist', 'teacher', 'engineer', 'artist', 'musician', 'writer',\n",
    "    #'denmark', 'sweden', 'france', 'germany', 'spain', 'italy', 'portugal', 'turkey',\n",
    "]\n",
    "selected_ids = [vectorizer.vocabulary_[word] for word in words_to_explore]\n",
    "selected_word_embeddings = word_embeddings[selected_ids, :]\n",
    "# Visualize the word embeddings using t-SNE or PCA for dimensionality reduction to 2D\n",
    "#tsne = TSNE(n_components=2, random_state=0)\n",
    "#projected_embs = tsne.fit_transform(selected_word_embeddings)\n",
    "pca = PCA(n_components=2)\n",
    "projected_embs = pca.fit_transform(selected_word_embeddings)[:,:2]\n",
    "\n",
    "\n",
    "# Visualize the word embeddings using PCA for dimensionality reduction to 2D\n",
    "projected_embs = PCA(n_components=2).fit_transform(selected_word_embeddings)[:,:2]\n",
    "\n",
    "plt.figure(figsize=(6,4), frameon=False)\n",
    "plt.scatter(projected_embs[:,0], projected_embs[:,1], edgecolors='k', c='r')\n",
    "for word, (x,y) in zip(words_to_explore, projected_embs):\n",
    "    plt.text(x+0.05, y+0.05, word)\n",
    "plt.xlabel('Dim 1', fontsize=10)\n",
    "plt.ylabel('Dim 2', fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.box(False)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fa279de7b9b5671",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:00:00.509524Z",
     "start_time": "2025-01-14T10:00:00.131087400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'king' and 'queen': 0.9401573365154285\n",
      "Top 5 similar words to 'king': [('coronation', 0.9438202898157546), ('queen', 0.9401573365154285), ('throne', 0.9365763575686025), ('crowned', 0.934686036005121), ('rhemuth', 0.9269274741745209)]\n"
     ]
    }
   ],
   "source": [
    "# Analyzing similarity between words\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def cosine_similarity_terms(word1, word2, word_embeddings_df):\n",
    "    vec1 = word_embeddings_df.loc[word1].values.reshape(1, -1)\n",
    "    vec2 = word_embeddings_df.loc[word2].values.reshape(1, -1)\n",
    "    similarity = cosine_similarity(vec1, vec2)\n",
    "    return similarity[0][0]\n",
    "\n",
    "# Find top 5 similar words for a given word\n",
    "def top_similar_words(word, word_embeddings_df, terms, top_n=5):\n",
    "    target_vector = word_embeddings_df.loc[word].values.reshape(1, -1)\n",
    "    similarities = cosine_similarity(word_embeddings_df, target_vector).flatten()\n",
    "    top_indices = np.argsort(similarities)[-top_n-1:-1][::-1]  # Exclude the word itself\n",
    "    similar_words = [(terms[i], similarities[i]) for i in top_indices]\n",
    "    return similar_words\n",
    "\n",
    "word_embeddings_df = pd.DataFrame(word_embeddings, index=terms)\n",
    "\n",
    "word1, word2 = \"king\", \"queen\"\n",
    "# Test cosine similarity function\n",
    "print(f\"Cosine similarity between '{word1}' and '{word2}': {cosine_similarity_terms(word1, word2, word_embeddings_df)}\")\n",
    "word = \"king\"\n",
    "print(f\"Top 5 similar words to '{word}': {top_similar_words(word, word_embeddings_df, terms, top_n=5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ea993e-949f-4f6a-b7d6-8cc0a3f01693",
   "metadata": {},
   "source": [
    "Compare Book Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3792e21df832835",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:00:02.962906Z",
     "start_time": "2025-01-14T10:00:00.161088400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary Similarities (Cosine Similarity):\n",
      "                Summary 1  Summary 2  Summary 3  Summary 4  Summary 5  \\\n",
      "Summary 1       1.000000  -0.036871   0.395550   0.318123  -0.015009   \n",
      "Summary 2      -0.036871   1.000000  -0.007497   0.143525   0.074623   \n",
      "Summary 3       0.395550  -0.007497   1.000000   0.065269  -0.144059   \n",
      "Summary 4       0.318123   0.143525   0.065269   1.000000   0.282950   \n",
      "Summary 5      -0.015009   0.074623  -0.144059   0.282950   1.000000   \n",
      "...                  ...        ...        ...        ...        ...   \n",
      "Summary 16555  -0.097693  -0.019470   0.164275   0.120111   0.227327   \n",
      "Summary 16556   0.327779   0.351161   0.354324  -0.106347  -0.296311   \n",
      "Summary 16557  -0.077746   0.101362  -0.025403   0.136211   0.009688   \n",
      "Summary 16558   0.220101   0.017644   0.300007   0.220255  -0.238999   \n",
      "Summary 16559   0.039455   0.084514   0.156596  -0.008125  -0.120293   \n",
      "\n",
      "               Summary 6  Summary 7  Summary 8  Summary 9  Summary 10  ...  \\\n",
      "Summary 1      -0.032043  -0.018210   0.468421  -0.191022    0.178939  ...   \n",
      "Summary 2      -0.095930  -0.142336   0.069389   0.320757    0.157529  ...   \n",
      "Summary 3      -0.167626  -0.152885   0.771958   0.037131    0.229190  ...   \n",
      "Summary 4      -0.030401   0.127745   0.068951  -0.252931    0.142958  ...   \n",
      "Summary 5      -0.038997   0.291236  -0.123151   0.395741    0.047129  ...   \n",
      "...                  ...        ...        ...        ...         ...  ...   \n",
      "Summary 16555   0.076745   0.475469   0.130988  -0.167376   -0.067794  ...   \n",
      "Summary 16556   0.019116  -0.244224   0.347076   0.000743    0.249510  ...   \n",
      "Summary 16557   0.156432  -0.116702  -0.027040   0.354552    0.046081  ...   \n",
      "Summary 16558  -0.054274  -0.174710   0.094118  -0.248334    0.071552  ...   \n",
      "Summary 16559  -0.029112  -0.197927   0.018609   0.023385   -0.043651  ...   \n",
      "\n",
      "               Summary 16550  Summary 16551  Summary 16552  Summary 16553  \\\n",
      "Summary 1           0.197641       0.177578       0.227497      -0.066630   \n",
      "Summary 2           0.097558      -0.085951       0.165725       0.102257   \n",
      "Summary 3           0.018865      -0.089554       0.145010       0.286822   \n",
      "Summary 4           0.097372       0.654868       0.222616      -0.105525   \n",
      "Summary 5           0.171471       0.102768      -0.024282      -0.173223   \n",
      "...                      ...            ...            ...            ...   \n",
      "Summary 16555       0.205313       0.110043      -0.046737       0.216716   \n",
      "Summary 16556       0.080593       0.003799       0.320529       0.229898   \n",
      "Summary 16557      -0.165788       0.391012       0.169001      -0.181707   \n",
      "Summary 16558      -0.007104       0.544123       0.385434       0.036145   \n",
      "Summary 16559      -0.218396       0.175341       0.090399       0.144302   \n",
      "\n",
      "               Summary 16554  Summary 16555  Summary 16556  Summary 16557  \\\n",
      "Summary 1           0.018728      -0.097693       0.327779      -0.077746   \n",
      "Summary 2           0.007094      -0.019470       0.351161       0.101362   \n",
      "Summary 3           0.119841       0.164275       0.354324      -0.025403   \n",
      "Summary 4          -0.098888       0.120111      -0.106347       0.136211   \n",
      "Summary 5           0.050703       0.227327      -0.296311       0.009688   \n",
      "...                      ...            ...            ...            ...   \n",
      "Summary 16555       0.125228       1.000000      -0.107833      -0.070980   \n",
      "Summary 16556       0.039281      -0.107833       1.000000      -0.105462   \n",
      "Summary 16557       0.292344      -0.070980      -0.105462       1.000000   \n",
      "Summary 16558       0.132099       0.024800       0.627608      -0.023938   \n",
      "Summary 16559       0.523748      -0.109817       0.200382       0.413697   \n",
      "\n",
      "               Summary 16558  Summary 16559  \n",
      "Summary 1           0.220101       0.039455  \n",
      "Summary 2           0.017644       0.084514  \n",
      "Summary 3           0.300007       0.156596  \n",
      "Summary 4           0.220255      -0.008125  \n",
      "Summary 5          -0.238999      -0.120293  \n",
      "...                      ...            ...  \n",
      "Summary 16555       0.024800      -0.109817  \n",
      "Summary 16556       0.627608       0.200382  \n",
      "Summary 16557      -0.023938       0.413697  \n",
      "Summary 16558       1.000000       0.066033  \n",
      "Summary 16559       0.066033       1.000000  \n",
      "\n",
      "[16559 rows x 16559 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the book summary vectors\n",
    "doc_embedding = U\n",
    "\n",
    "# Compute cosine similarity between documents\n",
    "doc_similarities = cosine_similarity(doc_embedding)\n",
    "doc_similarities_df = pd.DataFrame(\n",
    "    doc_similarities, columns=[f\"Summary {i+1}\" for i in range(len(corpus))], index=[f\"Summary {i+1}\" for i in range(len(corpus))])\n",
    "\n",
    "print(\"\\nSummary Similarities (Cosine Similarity):\\n\", doc_similarities_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9c0da9d1396235",
   "metadata": {},
   "source": [
    "**Question 2.** In this exercise, you will explore pre-trained word embeddings on the [Google News dataset](https://code.google.com/archive/p/word2vec/), and you will familiarize yourself with the **Gensim** package for handling the word embeddings. You will also investigate the analogy relationships between words based on their embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36b38cb2758cbac2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:00:04.149421600Z",
     "start_time": "2025-01-14T10:00:02.969291700Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim.test.utils import datapath\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98af1395fea97f1e",
   "metadata": {},
   "source": [
    "Download the pre-trained word embeddings from [Google News dataset](https://code.google.com/archive/p/word2vec/) and use the *Gensim* package to load and work with the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a11a28ec7600eba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:00:41.827811Z",
     "start_time": "2025-01-14T10:00:04.151421500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the path of the pretrained model\n",
    "googlenews_vectors = os.path.realpath(os.path.join(\n",
    "    os.getcwd(), './GoogleNews-vectors-negative300.bin.gz'\n",
    "))\n",
    "gensim_model = gensim.models.KeyedVectors.load_word2vec_format(googlenews_vectors, binary = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e820c33d4aa987b",
   "metadata": {},
   "source": [
    " Use the following example list of words: 'king', 'queen', 'woman', 'man', 'fish', 'bird', 'snake', 'elephant' (or construct your own list of at least $6$-$10$ meaningful and diverse words.\n",
    "\n",
    "Reduce the dimensionality of the word embeddings to $2D$ space using PCA and visualize the words in the new latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f17d9d6f8842524",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:00:42.239144400Z",
     "start_time": "2025-01-14T10:00:42.221116300Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def display_pca_scatterplot(model, words=None, sample=0, save=False, file_path='scatterplot.png'):\n",
    "    ### Inspired by the WI materials in 2023 and by http://web.stanford.edu/class/cs224n/\n",
    "    \n",
    "    assert words is None or sample == 0, f\"You must specify either words or sample, not both\"\n",
    "    \n",
    "    if words is None:\n",
    "        words = [ word for word in model.key_to_index.keys() ]\n",
    "    if sample > 0:\n",
    "        words = np.random.choice(list(model.key_to_index.keys()), sample)\n",
    "        \n",
    "    word_vectors = np.array([model[w] for w in words])\n",
    "\n",
    "    projected_embs = PCA(n_components=2).fit_transform(word_vectors)[:,:2]\n",
    "    \n",
    "    plt.figure(figsize=(6,4), frameon=False)\n",
    "    plt.scatter(projected_embs[:,0], projected_embs[:,1], edgecolors='k', c='r')\n",
    "    for word, (x,y) in zip(words, projected_embs):\n",
    "        plt.text(x+0.05, y+0.05, word)\n",
    "    plt.xlabel('Dim 1', fontsize=10)\n",
    "    plt.ylabel('Dim 2', fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.box(False)\n",
    "    if save:\n",
    "        plt.savefig(file_path)\n",
    "    else:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a83ecf0d99d9032d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:00:42.861542Z",
     "start_time": "2025-01-14T10:00:42.241730600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 600x400 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words_to_explore= [\n",
    "    'king', 'queen', 'woman', 'man', 'fish', 'bird', 'snake', 'elephant',\n",
    "]\n",
    "display_pca_scatterplot(model=gensim_model, words=words_to_explore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46908d4ea44dcea3",
   "metadata": {},
   "source": [
    "Investigate the relationships between the words based on their embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ee1332fcd75af78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:01:26.685955700Z",
     "start_time": "2025-01-14T10:00:42.870737900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[('queen', 0.7118193507194519),\n ('monarch', 0.6189674139022827),\n ('princess', 0.5902431011199951),\n ('crown_prince', 0.5499460697174072),\n ('prince', 0.5377321839332581),\n ('kings', 0.5236844420433044),\n ('Queen_Consort', 0.5235945582389832),\n ('queens', 0.5181134343147278),\n ('sultan', 0.5098593831062317),\n ('monarchy', 0.5087411999702454)]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_model.most_similar(positive=[\"king\", \"woman\"],negative=[\"man\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8857e8aa81b4689b",
   "metadata": {},
   "source": [
    "Assess the overall accuracy of the embeddings and analyze strengths and weaknesses across analogy types (syntactic vs. semantic).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69fa8e35e0103832",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:05:08.846825400Z",
     "start_time": "2025-01-14T10:01:26.711568500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall evaluation score: 0.7320405239459681\n",
      "Section: capital-common-countries - Correct: 421 - Incorrect: 85 - Accuracy: 0.8320158102766798\n",
      "Section: capital-world - Correct: 3552 - Incorrect: 972 - Accuracy: 0.7851458885941645\n",
      "Section: currency - Correct: 230 - Incorrect: 636 - Accuracy: 0.26558891454965355\n",
      "Section: city-in-state - Correct: 1779 - Incorrect: 688 - Accuracy: 0.72111876773409\n",
      "Section: family - Correct: 436 - Incorrect: 70 - Accuracy: 0.8616600790513834\n",
      "Section: gram1-adjective-to-adverb - Correct: 290 - Incorrect: 702 - Accuracy: 0.2923387096774194\n",
      "Section: gram2-opposite - Correct: 353 - Incorrect: 459 - Accuracy: 0.43472906403940886\n",
      "Section: gram3-comparative - Correct: 1216 - Incorrect: 116 - Accuracy: 0.9129129129129129\n",
      "Section: gram4-superlative - Correct: 987 - Incorrect: 135 - Accuracy: 0.8796791443850267\n",
      "Section: gram5-present-participle - Correct: 829 - Incorrect: 227 - Accuracy: 0.7850378787878788\n",
      "Section: gram6-nationality-adjective - Correct: 1442 - Incorrect: 157 - Accuracy: 0.9018136335209506\n",
      "Section: gram7-past-tense - Correct: 1020 - Incorrect: 540 - Accuracy: 0.6538461538461539\n",
      "Section: gram8-plural - Correct: 1159 - Incorrect: 173 - Accuracy: 0.8701201201201201\n",
      "Section: gram9-plural-verbs - Correct: 593 - Incorrect: 277 - Accuracy: 0.6816091954022988\n",
      "Section: Total accuracy - Correct: 14307 - Incorrect: 5237 - Accuracy: 0.7320405239459681\n"
     ]
    }
   ],
   "source": [
    "# print(\"Current Working Directory:\", datapath('./questions-words.txt'))\n",
    "\n",
    "accuracy = gensim_model.evaluate_word_analogies(datapath('./questions-words.txt'), dummy4unknown=True)\n",
    "\n",
    "\n",
    "\n",
    "# The first entry stores the overall evaluation score on the entire evaluation set\n",
    "print(f\"Overall evaluation score: {accuracy[0]}\")\n",
    "for current_dict in accuracy[1]:\n",
    "    correct_count, incorrect_count = len(current_dict['correct']), len(current_dict['incorrect'])\n",
    "    section_accuracy = correct_count / float(correct_count + incorrect_count)\n",
    "    print(\n",
    "        f\"Section: {current_dict['section']} - Correct: {correct_count} - Incorrect: {incorrect_count} - Accuracy: {section_accuracy}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1db6b95665a96b",
   "metadata": {},
   "source": [
    "**Question 3.** In this exercise, we will implement the **SkipGram** model of the **Word2Vec** framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f32bbfbd2f1a51a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:05:24.970121800Z",
     "start_time": "2025-01-14T10:05:08.858860800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b77001a-d9f5-4000-884a-dac31f84bec4",
   "metadata": {},
   "source": [
    "Prepare the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d35c617105e7cf54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:05:24.984467400Z",
     "start_time": "2025-01-14T10:05:24.971136Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = corpus # Define the corpus (preprocessed summaries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17a76a2c0543ae43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:05:27.254943900Z",
     "start_time": "2025-01-14T10:05:24.990414700Z"
    }
   },
   "outputs": [],
   "source": [
    "min_count = 5 # Discard the words that appear less or equal to 'min_count'\n",
    "window_size = 5 # You can choose small values to reduce computational cost, but it might affect the performance of the model\n",
    "\n",
    "from collections import Counter\n",
    "sentences = [sentence.split() for sentence in corpus]\n",
    "list_of_words = [word for sentence in sentences for word in sentence]\n",
    "vocab = set(list_of_words) \n",
    "word_counts = Counter(list_of_words)\n",
    "\n",
    "# Define the vocabulary, i.e. set of all distinct words that appear more than 'min_count' times in the corpus.\n",
    "vocab = set([word for word in vocab if word_counts[word] > min_count]) \n",
    "vocab_size = len(vocab) \n",
    "# Construct the dictionaries that maps words to unique ids and vice versa.\n",
    "word2Id = {word: id for id, word in enumerate(vocab)}\n",
    "id2Word = {id: word for word, id in word2Id.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cd887f9bc9930c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:05:58.703788500Z",
     "start_time": "2025-01-14T10:05:27.307820200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Generating center-context pairs:   0%|          | 0/16559 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0fd155d9aa1a4b3292278d0c5cf59164"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate skip-gram training (source, context) word pairs.\n",
    "\n",
    "# You can implement the following function to generate the source-context word pairs.\n",
    "# If you wish, you can also modify the argument list\n",
    "def generate_center_context_pairs(sentences, window_size, word2Id, vocab):\n",
    "    '''\n",
    "    Given a list of sentences and a window size, generate a pair of context pairs\n",
    "    Note that a pair must be discarded if its center or context word appears less than 'min_count'.\n",
    "    :param sentences: a list of lists of words\n",
    "    :param window_size: window size\n",
    "    :param word2Id: a dictionary that maps words to ids\n",
    "    :param vocab: a set of unique words\n",
    "    :return: a list of centerId-contextId word pairs\n",
    "    '''\n",
    "    data = []\n",
    "    for sentence in tqdm(sentences, desc=\"Generating center-context pairs\"):\n",
    "        for i, word in enumerate(sentence):\n",
    "            if word in vocab:\n",
    "                center_word_id = word2Id[word]\n",
    "                context_words = [sentence[i + j] for j in range(-window_size, window_size + 1) if j != 0 and 0 <= i + j < len(sentence)]\n",
    "                for context_word in context_words:\n",
    "                    if context_word in vocab:\n",
    "                        context_word_id = word2Id[context_word]\n",
    "                        data.append((center_word_id, context_word_id))\n",
    "                    #pass\n",
    "    return data\n",
    "\n",
    "pairs = generate_center_context_pairs(sentences=sentences, window_size=window_size, word2Id=word2Id, vocab=vocab)\n",
    "# Convert the list to a torch tensor\n",
    "pairs = torch.as_tensor(pairs, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f862e5643a37be1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:05:58.717296100Z",
     "start_time": "2025-01-14T10:05:58.705814300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 38312\n",
      "Number of center-context pairs: 34393094\n"
     ]
    }
   ],
   "source": [
    "# You can examine the training data\n",
    "print(f\"Vocab size: {vocab_size}\")\n",
    "print(f\"Number of center-context pairs: {pairs.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a810b49-ff78-4fce-b463-dbe6086e48d4",
   "metadata": {},
   "source": [
    "Implement the SkipGram Model with Softmax Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "481c0cc84f4bc310",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:05:58.775640900Z",
     "start_time": "2025-01-14T10:05:58.721753Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the Skip-gram Model with Softmax\n",
    "class SkipGramModel(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(SkipGramModel, self).__init__()\n",
    "        self.embeddings = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear = torch.nn.Linear(embedding_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, center_word):\n",
    "        # Embedding layer\n",
    "        embedding = self.embeddings(center_word)\n",
    "        # Linear layer with softmax for prediction\n",
    "        output = self.linear(embedding)\n",
    "        return output\n",
    "    \n",
    "    def get_center_embs(self, center_words = None):\n",
    "        if center_words is None:\n",
    "            return self.embeddings.weight\n",
    "        else:\n",
    "            return self.embeddings.weight.data[center_words]\n",
    "    \n",
    "    def get_context_embs(self, context_words):\n",
    "        if context_words is None:\n",
    "            return self.linear.weight\n",
    "        else:\n",
    "            return self.linear.weight.data[context_words, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3378e530-e6c6-4ae3-a341-214188724c2e",
   "metadata": {},
   "source": [
    "Set the parameters required for training the model such as learning rate, embedding dimension, epochs and batch size.\n",
    "Note that chosen values for the parameters might/might not affect the optimization and the training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ac3fce033366089",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:07:47.812507300Z",
     "start_time": "2025-01-14T10:07:47.763506300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "SkipGramModel(\n  (embeddings): Embedding(38312, 100)\n  (linear): Linear(in_features=100, out_features=38312, bias=True)\n)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.01\n",
    "epochs_num = 1\n",
    "embedding_dim = 100\n",
    "batch_size = 5000\n",
    "# batch_size = 512 \n",
    "# The batch size refers to the number of training examples processed together in a single forward and backward pass during training. It determines how much data is used at once to compute gradients and update model parameters.\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "model = SkipGramModel(vocab_size, embedding_dim)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Set the platform that we will use for training.\n",
    "device = torch.device('cpu') #torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") (for Mac M1/M2, torch.device('mps'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be088d20-658c-4c2d-8c0d-428139547dc6",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a76d1923acf6a2c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:11:13.966133900Z",
     "start_time": "2025-01-14T10:07:49.262964500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "544b2e1f3b0843689746af55cacd597e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Epoch 0 - Current batch progress:   0%|          | 0/6879 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "58ccf64f07574dd093ae75248ed1f3ec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <generator object tqdm.__iter__ at 0x00000247EC606500>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Software\\python\\Web Intelligence\\web-intelligence-course-sw7\\venv\\lib\\site-packages\\tqdm\\std.py\", line 1196, in __iter__\n",
      "    self.close()\n",
      "  File \"C:\\Software\\python\\Web Intelligence\\web-intelligence-course-sw7\\venv\\lib\\site-packages\\tqdm\\notebook.py\", line 272, in close\n",
      "    def close(self):\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[26], line 15\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# Forward pass\u001B[39;00m\n\u001B[0;32m     14\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 15\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcenter_word\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m# Calculate loss\u001B[39;00m\n\u001B[0;32m     18\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_function(output, context_word)\n",
      "File \u001B[1;32mC:\\Software\\python\\Web Intelligence\\web-intelligence-course-sw7\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\Software\\python\\Web Intelligence\\web-intelligence-course-sw7\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "Cell \u001B[1;32mIn[22], line 12\u001B[0m, in \u001B[0;36mSkipGramModel.forward\u001B[1;34m(self, center_word)\u001B[0m\n\u001B[0;32m     10\u001B[0m embedding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings(center_word)\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# Linear layer with softmax for prediction\u001B[39;00m\n\u001B[1;32m---> 12\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[43membedding\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "File \u001B[1;32mC:\\Software\\python\\Web Intelligence\\web-intelligence-course-sw7\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\Software\\python\\Web Intelligence\\web-intelligence-course-sw7\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32mC:\\Software\\python\\Web Intelligence\\web-intelligence-course-sw7\\venv\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Build a data loader for pairs vector in pytorch\n",
    "data_loader = DataLoader(pairs, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(epochs_num)):\n",
    "    total_loss = 0\n",
    "    for batch_pairs in tqdm(data_loader, desc=f\"Epoch {epoch} - Current batch progress\"):\n",
    "        # Transfer the batch data to the memory of the 'device' (i.e. gpu if used)\n",
    "        batch_pairs = batch_pairs.to(device)\n",
    "        # Define the center and context words\n",
    "        center_word, context_word = batch_pairs[:, 0], batch_pairs[:, 1]\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        output = model(center_word)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = loss_function(output, context_word)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(pairs):.4f}\")  \n",
    "        \n",
    "# Transfer the model back to the cpu.\n",
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cf308d-7632-4555-abae-41925623a583",
   "metadata": {},
   "source": [
    "Generate Word Embeddings and Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755f35fa41e5e0a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:07:41.306755100Z",
     "start_time": "2025-01-14T10:07:41.306755100Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "\n",
    "words_to_explore= [\n",
    "    'king', 'queen', 'woman', 'man', 'boy', 'daughter', \n",
    "    'dog', 'cat', 'horse', 'elephant', #'fish', 'bird', 'lizard', 'snake',\n",
    "    #'doctor', 'nurse', 'scientist', 'teacher', 'engineer', 'artist', 'musician', 'writer',\n",
    "    #'denmark', 'sweden', 'france', 'germany', 'spain', 'italy', 'portugal', 'turkey',\n",
    "]\n",
    "selected_ids = torch.tensor([word2Id[word] for word in words_to_explore])\n",
    "selected_word_embeddings = model.get_center_embs(selected_ids).detach()\n",
    "\n",
    "\n",
    "# Visualize the word embeddings using PCA for dimensionality reduction to 2D\n",
    "projected_embs = PCA(n_components=2).fit_transform(selected_word_embeddings)[:,:2]\n",
    "\n",
    "plt.figure(figsize=(6,4), frameon=False)\n",
    "plt.scatter(projected_embs[:,0], projected_embs[:,1], edgecolors='k', c='r')\n",
    "for word, (x,y) in zip(words_to_explore, projected_embs):\n",
    "    plt.text(x+0.05, y+0.05, word)\n",
    "plt.xlabel('Dim 1', fontsize=10)\n",
    "plt.ylabel('Dim 2', fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.box(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b986afc-127d-4bc6-8d2e-90c26062c9f5",
   "metadata": {},
   "source": [
    "Evaluate Word Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb3908622e06954",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:07:41.306755100Z",
     "start_time": "2025-01-14T10:07:41.306755100Z"
    }
   },
   "outputs": [],
   "source": [
    "names = [id2Word[i] for i in range(len(id2Word))]\n",
    "word_embs_df = pd.DataFrame(model.get_center_embs().detach(), index=names)\n",
    "\n",
    "word1, word2 = \"king\", \"queen\"\n",
    "# Test cosine similarity function\n",
    "print(f\"Cosine similarity between '{word1}' and '{word2}': {cosine_similarity_terms(word1, word2, word_embs_df)}\")\n",
    "word = \"king\"\n",
    "print(f\"Top 5 similar words to '{word}': {top_similar_words(word, word_embs_df, names, top_n=5)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7afdf4c81d7aee",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-14T10:07:41.306755100Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
